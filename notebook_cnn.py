# -*- coding: utf-8 -*-
"""Copia de PC2_GRAFICA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qC7mk6rpUJHW7Ev2huFFBYEl-ZX9dahn

# PC2 GR√ÅFICA - Sistema de Reconocimiento de Caracteres con CNN

Este notebook demuestra c√≥mo entrenar una Red Neuronal Convolucional (CNN) para reconocer caracteres escritos a mano. El sistema utiliza arquitecturas de deep learning modernas para lograr alta precisi√≥n en la clasificaci√≥n de caracteres.

## Contenido
1. [Configuraci√≥n del entorno](#1.-Configuraci√≥n-del-entorno)
2. [Estructura de datos y carga](#2.-Estructura-de-datos-y-carga)
3. [Carga y exploraci√≥n de datos](#3.-Carga-y-exploraci√≥n-de-datos)
4. [Preprocesamiento de im√°genes](#4.-Preprocesamiento-de-im√°genes)
5. [Arquitectura CNN](#5.-Arquitectura-CNN)
6. [Entrenamiento del modelo](#6.-Entrenamiento-del-modelo)
7. [Evaluaci√≥n del modelo](#7.-Evaluaci√≥n-del-modelo)
8. [An√°lisis post-entrenamiento](#8.-An√°lisis-post-entrenamiento)
9. [Predicciones con nuevas im√°genes](#9.-Predicciones-con-nuevas-im√°genes)
10. [Exportaci√≥n del modelo](#10.-Exportaci√≥n-del-modelo)
11. [Conclusiones](#11.-Conclusiones)

## 1. Configuraci√≥n del entorno

Primero, importamos las bibliotecas necesarias para nuestro proyecto, incluyendo TensorFlow para las CNN.
"""

# Commented out IPython magic to ensure Python compatibility.
# Importaci√≥n de bibliotecas necesarias
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import glob
from skimage import io, transform
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import pandas as pd
from sklearn.decomposition import PCA
from matplotlib import gridspec
import cv2

# TensorFlow y Keras para CNN
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Configuraci√≥n para visualizaciones
# %matplotlib inline
plt.style.use('ggplot')
plt.rcParams['figure.figsize'] = (12, 8)
sns.set_theme(style="whitegrid")

# Configuraci√≥n de TensorFlow
print(f"TensorFlow versi√≥n: {tf.__version__}")
print(f"GPU disponible: {tf.test.is_gpu_available()}")
if tf.test.is_gpu_available():
    print(f"Dispositivos GPU: {tf.config.list_physical_devices('GPU')}")

"""// ...existing code...
## 2. Estructura de datos y carga

### üíæ Archivos de datos requeridos:

Para que el sistema funcione correctamente, necesitas tener los siguientes archivos `.npy` en la carpeta `data/` (o la ruta que especifiques):

```
PC2/
‚îú‚îÄ‚îÄ data/                    # Carpeta principal de datos
‚îÇ   ‚îú‚îÄ‚îÄ X.npy               # Array NumPy con los datos de las im√°genes (N, H, W, C) o (N, H*W)
‚îÇ   ‚îú‚îÄ‚îÄ Y.npy               # Array NumPy con las etiquetas num√©ricas (N,)
‚îÇ   ‚îî‚îÄ‚îÄ clases.npy          # (Opcional) Array NumPy con los nombres de las clases.
‚îÇ                           # Si no se provee, las clases se inferir√°n de Y.npy.
‚îî‚îÄ‚îÄ PC2_GRAFICA.ipynb       # Este notebook
```

### üéØ Requisitos de los archivos `.npy`:

1.  **`X.npy`**:
    *   Debe ser un array NumPy.
    *   Puede tener forma `(N, H, W, C)` donde `N` es el n√∫mero de im√°genes, `H` la altura, `W` el ancho, y `C` el n√∫mero de canales (usualmente 1 para escala de grises).
    *   Alternativamente, puede tener forma `(N, F)` donde `F` es `H*W*C` (datos aplanados). La funci√≥n intentar√° remodelarlo.
    *   Se espera que los valores de p√≠xeles est√©n en el rango `[0, 255]` o ya normalizados a `[0, 1]`. La funci√≥n aplicar√° normalizaci√≥n si detecta valores mayores a 1.
2.  **`Y.npy`**:
    *   Debe ser un array NumPy de forma `(N,)` conteniendo las etiquetas num√©ricas (enteros) para cada imagen en `X.npy`.
3.  **`clases.npy`** (Opcional):
    *   Si se proporciona, debe ser un array NumPy conteniendo los nombres de las clases en el orden correspondiente a las etiquetas num√©ricas en `Y.npy`.
    *   Si no se proporciona, las clases se nombrar√°n como "Clase 0", "Clase 1", etc., basado en las etiquetas √∫nicas en `Y.npy`.

### üìã Instrucciones de preparaci√≥n:

1.  Crea la carpeta `data` en el mismo directorio que este notebook (o la ruta que desees usar).
2.  Coloca tus archivos `X.npy` e `Y.npy` (y opcionalmente `clases.npy`) en esta carpeta.
3.  Aseg√∫rate de que `X.npy` e `Y.npy` sean consistentes (mismo n√∫mero de muestras `N`).
// ...existing code...
"""

# ...existing code...
def cargar_datos_cnn(ruta_base='./data/', target_shape_hint=(64, 64, 1)):
    """
    Carga los datos desde archivos X.npy e Y.npy.
    Intenta remodelar X si es necesario y normaliza los valores de p√≠xeles.

    Args:
        ruta_base: Ruta base donde se encuentran los archivos .npy.
        target_shape_hint: Tupla (H, W, C) para ayudar a remodelar X si est√° aplanado
                           y para verificar la forma final.

    Returns:
        X: Im√°genes normalizadas para CNN (N, H, W, C)
        y: Etiquetas num√©ricas (N,)
        clases: Lista de clases √∫nicas (nombres)
        label_to_class: Diccionario de mapeo de etiquetas num√©ricas a nombres de clase
    """
    ruta_X = os.path.join(ruta_base, 'X.npy')
    ruta_y = os.path.join(ruta_base, 'Y.npy')
    ruta_clases_npy = os.path.join(ruta_base, 'clases.npy')

    if not os.path.exists(ruta_X) or not os.path.exists(ruta_y):
        raise FileNotFoundError(
            f"No se encontraron 'X.npy' o 'Y.npy' en {ruta_base}. "
            "Por favor, aseg√∫rate de que los archivos existen."
        )

    print(f"Cargando datos desde {ruta_X} y {ruta_y}...")
    X = np.load(ruta_X)
    y = np.load(ruta_y)

    print(f"Forma original de X: {X.shape}")
    print(f"Forma original de y: {y.shape}")

    # Validar consistencia
    if X.shape[0] != y.shape[0]:
        raise ValueError(
            f"Inconsistencia en el n√∫mero de muestras: X tiene {X.shape[0]} y Y tiene {y.shape[0]}"
        )

    # Remodelar X si es necesario
    N = X.shape[0]
    H, W, C = target_shape_hint

    if X.ndim == 2: # (N, Features_aplanadas)
        expected_features = H * W * C
        if X.shape[1] == H * W: # Asumiendo C=1 si no se especifica en target_shape_hint o es impl√≠cito
             if C == 1 and target_shape_hint[2] !=1: # Si el hint tenia C > 1 pero X.shape[1] solo cubre H*W
                 print(f"Advertencia: X.shape[1] ({X.shape[1]}) coincide con H*W ({H*W}). Asumiendo C=1.")
             X = X.reshape(N, H, W, 1) # Asumir C=1 si solo H*W coincide
        elif X.shape[1] == expected_features:
            X = X.reshape(N, H, W, C)
        else:
            raise ValueError(
                f"X est√° aplanado con {X.shape[1]} caracter√≠sticas, "
                f"pero se esperaban {expected_features} (para {H}x{W}x{C}) o {H*W} (para {H}x{W}x1)."
                "Verifica target_shape_hint."
            )
        print(f"X remodelado a: {X.shape}")
    elif X.ndim == 3: # (N, H, W) -> A√±adir canal
        X = np.expand_dims(X, axis=-1)
        print(f"X expandido a: {X.shape}")
    elif X.ndim == 4: # (N, H, W, C)
        print("X ya tiene 4 dimensiones, no se requiere remodelaci√≥n.")
    else:
        raise ValueError(f"Forma de X no soportada: {X.shape}. Se espera 2D, 3D o 4D.")

    # Verificar forma final con target_shape_hint
    if X.shape[1:] != target_shape_hint:
         print(
            f"Advertencia: La forma de X procesado {X.shape[1:]} no coincide exactamente con target_shape_hint {target_shape_hint}."
            "Continuando, pero revisa tus datos y el hint."
        )


    # Normalizar X a [0, 1] si no lo est√° ya
    if X.max() > 1.0:
        print("Normalizando X a [0, 1] (dividiendo por 255.0)...")
        X = X.astype(np.float32) / 255.0
    else:
        print("X parece estar ya normalizado (max <= 1.0).")

    X = X.astype(np.float32) # Asegurar float32 para TensorFlow

    # Cargar o generar nombres de clases
    if os.path.exists(ruta_clases_npy):
        clases_nombres = np.load(ruta_clases_npy, allow_pickle=True)
        print(f"Nombres de clases cargados desde {ruta_clases_npy}: {clases_nombres}")
        # Validar que el n√∫mero de clases coincida con las etiquetas
        unique_labels = np.unique(y)
        if len(clases_nombres) < len(unique_labels):
            raise ValueError(
                f"El archivo 'clases.npy' tiene {len(clases_nombres)} nombres, "
                f"pero se encontraron {len(unique_labels)} etiquetas √∫nicas en Y.npy."
            )
        # Tomar solo los nombres necesarios si clases_nombres es m√°s largo (podr√≠a tener nombres para etiquetas no presentes)
        clases_nombres = [clases_nombres[i] for i in sorted(unique_labels)]

    else:
        print("No se encontr√≥ 'clases.npy'. Generando nombres de clase por defecto.")
        unique_labels = sorted(list(np.unique(y)))
        clases_nombres = [f"Clase {label}" for label in unique_labels]

    label_to_class = {i: nombre for i, nombre in enumerate(clases_nombres)}
    # Asegurar que 'y' use √≠ndices de 0 a num_clases-1 si es necesario
    # Esto es importante si las etiquetas en Y.npy no son secuenciales desde 0
    map_original_to_sequential = {original_label: sequential_label for sequential_label, original_label in enumerate(sorted(np.unique(y)))}
    y_sequential = np.array([map_original_to_sequential[val] for val in y])


    print(f"Datos cargados: {X.shape[0]} im√°genes.")
    print(f"N√∫mero de clases detectadas/cargadas: {len(clases_nombres)}")
    print(f"Forma final de X: {X.shape} (N, H, W, C)")
    print(f"Forma final de y: {y_sequential.shape}")

    return X, y_sequential, clases_nombres, label_to_class
#...existing code...

"""## 3. Carga y exploraci√≥n de datos

Cargamos los datos y exploramos su estructura con visualizaciones espec√≠ficas para CNN.
"""

# ...existing code...
# Cargamos los datos desde .npy
# Define el target_shape_hint (H, W, C) esperado para tus im√°genes despu√©s de la carga y remodelaci√≥n.
# Por ejemplo, si tus im√°genes son 64x64 en escala de grises:
EXPECTED_IMG_HEIGHT = 64
EXPECTED_IMG_WIDTH = 64
EXPECTED_IMG_CHANNELS = 1
target_shape_hint = (EXPECTED_IMG_HEIGHT, EXPECTED_IMG_WIDTH, EXPECTED_IMG_CHANNELS)

try:
    X, y, clases, label_to_class = cargar_datos_cnn(ruta_base='./data/', target_shape_hint=target_shape_hint)

    # Informaci√≥n b√°sica sobre el conjunto de datos
    print(f"\nInformaci√≥n del dataset:")
    print(f"Forma de X: {X.shape}")
    print(f"Tipo de datos de X: {X.dtype}")
    print(f"Rango de valores en X: [{X.min():.3f}, {X.max():.3f}]")
    print(f"Forma de y: {y.shape}")
    print(f"Tipo de datos de y: {y.dtype}")
    print(f"Clases encontradas/definidas: {clases}")
    print(f"Mapeo de etiquetas: {label_to_class}")

    # Distribuci√≥n de clases
    unique_labels_in_y, counts = np.unique(y, return_counts=True)
    distribucion = {label_to_class[label]: count for label, count in zip(unique_labels_in_y, counts)}

    print("\nDistribuci√≥n de clases:")
    for clase_nombre, cantidad in distribucion.items():
        print(f"  {clase_nombre}: {cantidad} im√°genes")

    # Visualizaci√≥n de la distribuci√≥n
    plt.figure(figsize=(10, 6))
    class_names_for_plot = [label_to_class[i] for i in unique_labels_in_y] # Usar los nombres de clase correctos
    plt.bar(class_names_for_plot, counts, color='skyblue', edgecolor='navy', alpha=0.7)
    plt.xlabel('Clases')
    plt.ylabel('N√∫mero de im√°genes')
    plt.title('Distribuci√≥n de im√°genes por clase')
    plt.xticks(rotation=45, ha="right") # Rotar etiquetas si son muchas
    plt.grid(axis='y', alpha=0.3)
    for i, count in enumerate(counts):
        plt.text(i, count + max(counts)*0.01, str(count), ha='center', va='bottom') # Ajustar posici√≥n del texto
    plt.tight_layout() # Ajustar layout para evitar superposiciones
    plt.show()

except FileNotFoundError as e:
    print(e)
    print("Por favor, crea los archivos X.npy e Y.npy en la carpeta './data/' o especifica la ruta correcta.")
    # Detener la ejecuci√≥n o manejar el error como prefieras
    X, y, clases, label_to_class = (None, None, None, None) # Para evitar errores en celdas posteriores si no se cargan
except ValueError as e:
    print(f"Error al procesar los datos: {e}")
    X, y, clases, label_to_class = (None, None, None, None)

# ... El resto de la celda puede continuar, pero aseg√∫rate de que X, y, etc., no sean None
# ...existing code...

def visualizar_ejemplos_cnn(X, y, clases, label_to_class, n_ejemplos=6):
    """Visualiza ejemplos de cada clase optimizado para datos de CNN"""
    n_clases = len(clases)
    fig, axes = plt.subplots(n_clases, n_ejemplos, figsize=(n_ejemplos*2, n_clases*2.5))

    if n_clases == 1:
        axes = axes.reshape(1, -1)

    for i, clase in enumerate(clases):
        # Obtener √≠ndices de esta clase
        indices = np.where(y == i)[0]
        # Seleccionar aleatoriamente n_ejemplos
        seleccionados = np.random.choice(indices, min(n_ejemplos, len(indices)), replace=False)

        for j, idx in enumerate(seleccionados):
            ax = axes[i, j]
            # Mostrar imagen (squeeze para remover dimensi√≥n de canal si es necesario)
            img_display = X[idx].squeeze()
            ax.imshow(img_display, cmap='gray')
            ax.set_title(f'{clase} ({idx})', fontsize=10)
            ax.axis('off')

            # Agregar informaci√≥n de la imagen
            ax.text(0.02, 0.98, f'Shape: {X[idx].shape}\nMin: {X[idx].min():.2f}\nMax: {X[idx].max():.2f}',
                   transform=ax.transAxes, fontsize=8, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

    plt.tight_layout()
    plt.suptitle('Ejemplos de im√°genes por clase (Datos preparados para CNN)', y=1.02, fontsize=16)
    plt.show()

# Visualizar ejemplos
visualizar_ejemplos_cnn(X, y, clases, label_to_class)

"""## 4. Preprocesamiento de im√°genes

Preparamos los datos espec√≠ficamente para entrenamiento con CNN, incluyendo divisi√≥n de conjuntos y codificaci√≥n categ√≥rica.
"""

# Convertir etiquetas a formato categ√≥rico (one-hot encoding)
num_classes = len(clases)
y_categorical = to_categorical(y, num_classes)

print(f"Forma original de y: {y.shape}")
print(f"Forma categ√≥rica de y: {y_categorical.shape}")
print(f"Ejemplo de codificaci√≥n:")
for i in range(min(3, len(y))):
    print(f"  Clase {label_to_class[y[i]]} -> {y[i]} -> {y_categorical[i]}")

# Dividir en conjuntos de entrenamiento, validaci√≥n y prueba
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y_categorical, test_size=0.2, random_state=42, stratify=y
)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp.argmax(axis=1)
)

print(f"\nDivisi√≥n de datos:")
print(f"Entrenamiento: {X_train.shape[0]} im√°genes ({X_train.shape[0]/len(X)*100:.1f}%)")
print(f"Validaci√≥n: {X_val.shape[0]} im√°genes ({X_val.shape[0]/len(X)*100:.1f}%)")
print(f"Prueba: {X_test.shape[0]} im√°genes ({X_test.shape[0]/len(X)*100:.1f}%)")

# Verificar las formas finales
print(f"\nFormas finales:")
print(f"X_train: {X_train.shape}")
print(f"X_val: {X_val.shape}")
print(f"X_test: {X_test.shape}")
print(f"y_train: {y_train.shape}")
print(f"y_val: {y_val.shape}")
print(f"y_test: {y_test.shape}")

"""## 5. Arquitectura CNN

Definimos la arquitectura de la Red Neuronal Convolucional con capas optimizadas para reconocimiento de caracteres.

### üèóÔ∏è Arquitectura propuesta:
- **Capas Convolucionales**: Para extracci√≥n de caracter√≠sticas
- **Pooling**: Para reducci√≥n de dimensionalidad
- **Batch Normalization**: Para estabilidad del entrenamiento
- **Dropout**: Para prevenir overfitting
- **Capas densas**: Para clasificaci√≥n final
"""

def crear_modelo_cnn(input_shape, num_classes, arquitectura='basica'):
    """
    Crea un modelo CNN para reconocimiento de caracteres

    Args:
        input_shape: Forma de entrada (height, width, channels)
        num_classes: N√∫mero de clases a clasificar
        arquitectura: 'basica', 'intermedia' o 'avanzada'

    Returns:
        model: Modelo CNN compilado
    """

    if arquitectura == 'basica':
        model = Sequential([
            # Primera capa convolucional
            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
            BatchNormalization(),
            MaxPooling2D((2, 2)),

            # Segunda capa convolucional
            Conv2D(64, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),

            # Tercera capa convolucional
            Conv2D(128, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),

            # Aplanar para capas densas
            Flatten(),

            # Capas densas
            Dense(128, activation='relu'),
            Dropout(0.5),
            Dense(64, activation='relu'),
            Dropout(0.3),
            Dense(num_classes, activation='softmax')
        ])

    elif arquitectura == 'intermedia':
        model = Sequential([
            # Primer bloque convolucional
            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
            Conv2D(32, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.25),

            # Segundo bloque convolucional
            Conv2D(64, (3, 3), activation='relu'),
            Conv2D(64, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.25),

            # Tercer bloque convolucional
            Conv2D(128, (3, 3), activation='relu'),
            Conv2D(128, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.25),

            # Capas densas
            Flatten(),
            Dense(256, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(128, activation='relu'),
            Dropout(0.3),
            Dense(num_classes, activation='softmax')
        ])

    else:  # avanzada
        model = Sequential([
            # Primer bloque
            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),

            # Segundo bloque
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),

            # Tercer bloque
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),

            # Cuarto bloque
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),

            # Capas densas
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(256, activation='relu'),
            BatchNormalization(),
            Dropout(0.4),
            Dense(128, activation='relu'),
            Dropout(0.3),
            Dense(num_classes, activation='softmax')
        ])

    return model

# Crear el modelo
input_shape = X_train.shape[1:]  # (height, width, channels)
print(f"Forma de entrada: {input_shape}")
print(f"N√∫mero de clases: {num_classes}")

# Seleccionar arquitectura (puedes cambiar entre 'basica', 'intermedia', 'avanzada')
arquitectura_elegida = 'intermedia'
model = crear_modelo_cnn(input_shape, num_classes, arquitectura_elegida)

# Compilar el modelo
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Mostrar resumen del modelo
print(f"\nüèóÔ∏è Arquitectura seleccionada: {arquitectura_elegida}")
print("="*50)
model.summary()

# Visualizar la arquitectura
try:
    tf.keras.utils.plot_model(
        model,
        to_file='modelo_arquitectura.png',
        show_shapes=True,
        show_layer_names=True,
        rankdir='TB',
        dpi=150
    )
    print("\nüìä Diagrama de arquitectura guardado como 'modelo_arquitectura.png'")
except:
    print("\n‚ö†Ô∏è No se pudo generar el diagrama de arquitectura (requiere graphviz)")

"""## 6. Entrenamiento del modelo

Entrenamos la CNN con callbacks para optimizar el proceso de entrenamiento.
"""

# Configurar callbacks para un entrenamiento eficiente
callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    ),
    ModelCheckpoint(
        filepath='mejor_modelo.h5',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )
]

# Configuraci√≥n de entrenamiento
EPOCHS = 50
BATCH_SIZE = 32

print(f"üöÄ Iniciando entrenamiento:")
print(f"√âpocas m√°ximas: {EPOCHS}")
print(f"Tama√±o de batch: {BATCH_SIZE}")
print(f"Callbacks configurados: {len(callbacks)}")
print("="*50)

# Entrenar el modelo
history = model.fit(
    X_train, y_train,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=(X_val, y_val),
    callbacks=callbacks,
    verbose=1
)

print("\n‚úÖ Entrenamiento completado!")

# Visualizar las curvas de entrenamiento
def plot_training_history(history):
    """Visualiza las m√©tricas de entrenamiento"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    # Accuracy
    ax1.plot(history.history['accuracy'], label='Entrenamiento', color='blue')
    ax1.plot(history.history['val_accuracy'], label='Validaci√≥n', color='orange')
    ax1.set_title('Precisi√≥n del Modelo')
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('Precisi√≥n')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Loss
    ax2.plot(history.history['loss'], label='Entrenamiento', color='blue')
    ax2.plot(history.history['val_loss'], label='Validaci√≥n', color='orange')
    ax2.set_title('P√©rdida del Modelo')
    ax2.set_xlabel('√âpoca')
    ax2.set_ylabel('P√©rdida')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Mostrar m√©tricas finales
    final_train_acc = history.history['accuracy'][-1]
    final_val_acc = history.history['val_accuracy'][-1]
    final_train_loss = history.history['loss'][-1]
    final_val_loss = history.history['val_loss'][-1]

    print(f"\nüìä M√©tricas finales:")
    print(f"Precisi√≥n entrenamiento: {final_train_acc:.4f}")
    print(f"Precisi√≥n validaci√≥n: {final_val_acc:.4f}")
    print(f"P√©rdida entrenamiento: {final_train_loss:.4f}")
    print(f"P√©rdida validaci√≥n: {final_val_loss:.4f}")

    # Detectar overfitting
    if final_train_acc - final_val_acc > 0.1:
        print("‚ö†Ô∏è Posible overfitting detectado (diferencia > 10%)")
    else:
        print("‚úÖ Buen balance entre entrenamiento y validaci√≥n")

plot_training_history(history)

"""## 7. Evaluaci√≥n del modelo

Evaluamos el rendimiento del modelo CNN en el conjunto de prueba.
"""

# Cargar el mejor modelo guardado durante el entrenamiento
print("Cargando el mejor modelo entrenado (mejor_modelo.h5)...")
model = keras.models.load_model('mejor_modelo.h5')
print("Modelo cargado exitosamente.")

# Evaluar en conjunto de prueba
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"üìà Resultados en conjunto de prueba:")
print(f"Precisi√≥n: {test_accuracy:.4f}")
print(f"P√©rdida: {test_loss:.4f}")

# Predicciones en conjunto de prueba
y_pred_proba = model.predict(X_test)
y_pred = np.argmax(y_pred_proba, axis=1)
y_test_labels = np.argmax(y_test, axis=1)

# Reporte de clasificaci√≥n
print("\nüìã Informe de clasificaci√≥n:")
print(classification_report(y_test_labels, y_pred, target_names=clases))

# Matriz de confusi√≥n
cm = confusion_matrix(y_test_labels, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=clases, yticklabels=clases)
plt.xlabel('Predicci√≥n')
plt.ylabel('Valor real')
plt.title('Matriz de confusi√≥n - Conjunto de prueba', fontsize=16)
plt.tight_layout()
plt.show()

# Calcular m√©tricas adicionales por clase
from sklearn.metrics import precision_recall_fscore_support

precision, recall, f1, support = precision_recall_fscore_support(
    y_test_labels, y_pred, average=None
)

metrics_df = pd.DataFrame({
    'Clase': clases,
    'Precisi√≥n': precision,
    'Recall': recall,
    'F1-Score': f1,
    'Soporte': support
})

print("\nüìä M√©tricas detalladas por clase:")
print(metrics_df.round(4))

"""## 8. An√°lisis post-entrenamiento

Realizamos un an√°lisis exhaustivo de los errores del modelo y visualizamos las activaciones de las capas convolucionales.
"""

# An√°lisis detallado de errores
def analizar_errores_cnn(X_test, y_test, y_pred, y_pred_proba, label_to_class, max_errores=15):
    """An√°lisis comprehensivo de errores del modelo CNN"""

    # Encontrar √≠ndices de errores
    y_test_labels = np.argmax(y_test, axis=1)
    errores_idx = np.where(y_test_labels != y_pred)[0]

    print(f"üìä An√°lisis de errores:")
    print(f"Total de errores: {len(errores_idx)} de {len(y_test)} ({len(errores_idx)/len(y_test)*100:.2f}%)")

    if len(errores_idx) == 0:
        print("üéâ ¬°No hay errores para analizar!")
        return

    # Analizar tipos de errores m√°s comunes
    errores_df = pd.DataFrame({
        'Real': [label_to_class[label] for label in y_test_labels[errores_idx]],
        'Predicho': [label_to_class[label] for label in y_pred[errores_idx]],
        'Confianza': np.max(y_pred_proba[errores_idx], axis=1)
    })

    print("\nüîç Tipos de errores m√°s comunes:")
    error_counts = errores_df.groupby(['Real', 'Predicho']).size().reset_index(name='Cantidad')
    error_counts = error_counts.sort_values('Cantidad', ascending=False)
    print(error_counts.head(10))

    # Visualizar errores con menor confianza (m√°s inciertos)
    errores_ordenados = errores_idx[np.argsort(np.max(y_pred_proba[errores_idx], axis=1))]

    n_mostrar = min(max_errores, len(errores_ordenados))
    n_cols = 5
    n_rows = (n_mostrar + n_cols - 1) // n_cols

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))
    axes = axes.flatten() if n_rows > 1 else [axes] if n_mostrar == 1 else axes

    for i in range(n_mostrar):
        idx = errores_ordenados[i]
        img = X_test[idx].squeeze()
        real = y_test_labels[idx]
        pred = y_pred[idx]
        confianza = np.max(y_pred_proba[idx])

        ax = axes[i]
        ax.imshow(img, cmap='gray')
        ax.set_title(f'Real: {label_to_class[real]}\nPred: {label_to_class[pred]}\nConf: {confianza:.3f}',
                    fontsize=10, color='red')
        ax.axis('off')

        # Mostrar top 3 predicciones
        top_3_idx = np.argsort(y_pred_proba[idx])[-3:][::-1]
        prob_text = '\n'.join([f'{label_to_class[j]}: {y_pred_proba[idx][j]:.3f}'
                              for j in top_3_idx])
        ax.text(0.02, 0.02, prob_text, transform=ax.transAxes, fontsize=8,
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),
                verticalalignment='bottom')

    # Ocultar ejes no utilizados
    for i in range(n_mostrar, len(axes)):
        axes[i].axis('off')

    plt.tight_layout()
    plt.suptitle('Errores con menor confianza (m√°s inciertos)', y=1.02, fontsize=16)
    plt.show()

    return errores_df

# Ejecutar an√°lisis de errores
errores_df = analizar_errores_cnn(X_test, y_test, y_pred, y_pred_proba, label_to_class)

# Visualizaci√≥n de activaciones de capas convolucionales
def visualizar_activaciones(model, X_test, idx_imagen=0, capas_conv=None):
    """Visualiza las activaciones de las capas convolucionales"""

    if capas_conv is None:
        # Obtener autom√°ticamente las primeras capas convolucionales
        capas_conv = []
        for i, layer in enumerate(model.layers):
            if isinstance(layer, Conv2D):
                capas_conv.append(i)
            if len(capas_conv) >= 4:  # Limitar a las primeras 4 capas conv
                break

    if not capas_conv:
        print("No se encontraron capas convolucionales en el modelo")
        return

    # Crear modelo para extraer activaciones
    outputs = [model.layers[i].output for i in capas_conv]
    activation_model = keras.Model(inputs=model.input, outputs=outputs)

    # Obtener activaciones para una imagen
    img_input = np.expand_dims(X_test[idx_imagen], axis=0)
    activations = activation_model.predict(img_input, verbose=0)

    # Visualizar imagen original
    plt.figure(figsize=(15, 2 + len(capas_conv) * 3))

    # Imagen original
    plt.subplot(len(capas_conv) + 1, 1, 1)
    plt.imshow(X_test[idx_imagen].squeeze(), cmap='gray')
    plt.title('Imagen Original')
    plt.axis('off')

    # Visualizar activaciones de cada capa
    for i, (capa_idx, activation) in enumerate(zip(capas_conv, activations)):
        layer_name = model.layers[capa_idx].name

        # Mostrar algunos filtros de la activaci√≥n
        n_features = min(16, activation.shape[-1])  # M√°ximo 16 filtros
        n_cols = 8
        n_rows = (n_features + n_cols - 1) // n_cols

        plt.subplot(len(capas_conv) + 1, 1, i + 2)
        fig_temp, axes_temp = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 1.5))
        if n_rows == 1:
            axes_temp = axes_temp.reshape(1, -1)

        for j in range(n_features):
            row = j // n_cols
            col = j % n_cols
            axes_temp[row, col].imshow(activation[0, :, :, j], cmap='viridis')
            axes_temp[row, col].set_title(f'Filtro {j}', fontsize=8)
            axes_temp[row, col].axis('off')

        # Ocultar axes no utilizados
        for j in range(n_features, n_rows * n_cols):
            row = j // n_cols
            col = j % n_cols
            axes_temp[row, col].axis('off')

        plt.suptitle(f'Activaciones - {layer_name}', fontsize=12)
        plt.tight_layout()
        plt.show()

# Visualizar activaciones para una imagen de prueba
print("üîç Visualizaci√≥n de activaciones de capas convolucionales:")
try:
    visualizar_activaciones(model, X_test, idx_imagen=0)
except Exception as e:
    print(f"Error al visualizar activaciones: {e}")

# An√°lisis de confianza de predicciones
def analizar_confianza_predicciones(y_pred_proba, y_test, y_pred, label_to_class):
    """Analiza la distribuci√≥n de confianza de las predicciones"""

    y_test_labels = np.argmax(y_test, axis=1)
    confianzas = np.max(y_pred_proba, axis=1)
    correctas = (y_pred == y_test_labels)

    # Estad√≠sticas de confianza
    print("üìä An√°lisis de confianza de predicciones:")
    print(f"Confianza promedio (correctas): {confianzas[correctas].mean():.4f}")
    print(f"Confianza promedio (incorrectas): {confianzas[~correctas].mean():.4f}")
    print(f"Confianza m√≠nima: {confianzas.min():.4f}")
    print(f"Confianza m√°xima: {confianzas.max():.4f}")

    # Visualizar distribuci√≥n de confianza
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))

    # Histograma de confianza
    ax1.hist(confianzas[correctas], bins=30, alpha=0.7, label='Correctas', color='green')
    ax1.hist(confianzas[~correctas], bins=30, alpha=0.7, label='Incorrectas', color='red')
    ax1.set_xlabel('Confianza')
    ax1.set_ylabel('Frecuencia')
    ax1.set_title('Distribuci√≥n de Confianza')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Precisi√≥n por nivel de confianza
    bins = np.linspace(0, 1, 11)
    bin_centers = (bins[:-1] + bins[1:]) / 2
    accuracies = []

    for i in range(len(bins) - 1):
        mask = (confianzas >= bins[i]) & (confianzas < bins[i+1])
        if mask.sum() > 0:
            acc = correctas[mask].mean()
            accuracies.append(acc)
        else:
            accuracies.append(0)

    ax2.plot(bin_centers, accuracies, 'o-', linewidth=2, markersize=8)
    ax2.set_xlabel('Nivel de Confianza')
    ax2.set_ylabel('Precisi√≥n')
    ax2.set_title('Precisi√≥n vs Nivel de Confianza')
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(0, 1.05)

    # Matriz de confianza por clase
    confianza_por_clase = []
    for clase_idx in range(len(label_to_class)):
        mask = y_test_labels == clase_idx
        if mask.sum() > 0:
            confianza_por_clase.append(confianzas[mask].mean())
        else:
            confianza_por_clase.append(0)

    ax3.bar(range(len(label_to_class)), confianza_por_clase, color='skyblue', edgecolor='navy')
    ax3.set_xlabel('Clase')
    ax3.set_ylabel('Confianza Promedio')
    ax3.set_title('Confianza Promedio por Clase')
    ax3.set_xticks(range(len(label_to_class)))
    ax3.set_xticklabels([label_to_class[i] for i in range(len(label_to_class))])
    ax3.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.show()

    return confianzas, correctas

# Ejecutar an√°lisis de confianza
confianzas, correctas = analizar_confianza_predicciones(y_pred_proba, y_test, y_pred, label_to_class)

"""## 9. Predicciones con nuevas im√°genes

Creamos una funci√≥n optimizada para hacer predicciones con nuevas im√°genes usando el modelo CNN entrenado.
"""

def predecir_imagen_cnn(imagen_path, model, label_to_class, target_size=(64, 64),
                       mostrar_activaciones=False, aplicar_ajuste_contraste_camara=False):
    """
    Predice la clase de una nueva imagen usando el modelo CNN entrenado

    Args:
        imagen_path: Ruta a la imagen para predecir
        model: Modelo CNN entrenado
        label_to_class: Diccionario de mapeo de etiquetas a clases
        target_size: Tama√±o objetivo para redimensionar la imagen
        mostrar_activaciones: Si mostrar activaciones de capas conv
        aplicar_ajuste_contraste_camara: Si aplicar ajuste de contraste para fotos de c√°mara

    Returns:
        pred_class: Clase predicha
        confidence: Confianza de la predicci√≥n
        probs: Probabilidades para todas las clases
    """
    try:
        # Cargar y preprocesar la imagen
        img = io.imread(imagen_path)

        # Preprocesamiento similar al entrenamiento
        if img.ndim == 3:
            if img.shape[2] == 4:  # RGBA
                img = img[:, :, 3]  # Usar canal alfa
            else:  # RGB
                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

        # Aplicar ajuste de contraste si es para imagen de c√°mara
        if aplicar_ajuste_contraste_camara:
            img_float = img.astype(np.float32)
            contrast_factor = 1.5 # Mismo factor que en el entrenamiento
            img_contrasted = (img_float - 128.0) * contrast_factor + 128.0
            img_contrasted = np.clip(img_contrasted, 0, 255)
            img = img_contrasted.astype(np.uint8)
            print("Ajuste de contraste aplicado a la imagen de c√°mara.")

        # Redimensionar
        img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) # Renombrar para claridad

        # Normalizar
        img_normalized = img_resized.astype(np.float32) / 255.0 # Renombrar para claridad

        # A√±adir dimensiones (batch, height, width, channels)
        img_input = np.expand_dims(np.expand_dims(img_normalized, axis=-1), axis=0)

        # Visualizar imagen preprocesada
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))

        # Imagen original
        img_original = io.imread(imagen_path)
        if img_original.ndim == 3 and img_original.shape[2] > 3:
            img_original = img_original[:, :, :3]
        axes[0].imshow(img_original if img_original.ndim == 3 else img_original,
                      cmap='gray' if img_original.ndim == 2 else None)
        axes[0].set_title('Imagen Original')
        axes[0].axis('off')

        # Imagen preprocesada (antes de normalizar para visualizaci√≥n, o la normalizada)
        axes[1].imshow(img_resized, cmap='gray') # Mostrar img_resized para ver efecto de contraste
        axes[1].set_title(f'Imagen Preprocesada\n({target_size[0]}x{target_size[1]})')
        axes[1].axis('off')

        plt.tight_layout()
        plt.show()

        # Hacer predicci√≥n
        predictions = model.predict(img_input, verbose=0)
        pred_idx = np.argmax(predictions[0])
        pred_class = label_to_class[pred_idx]
        confidence = predictions[0][pred_idx]

        # Mostrar resultados
        print(f"üéØ Resultado de la predicci√≥n:")
        print(f"Clase predicha: {pred_class}")
        print(f"Confianza: {confidence:.4f} ({confidence*100:.2f}%)")

        # Mostrar todas las probabilidades
        print(f"\nüìä Probabilidades por clase:")
        sorted_indices = np.argsort(predictions[0])[::-1]
        for i, idx in enumerate(sorted_indices):
            prob = predictions[0][idx]
            print(f"  {i+1}. {label_to_class[idx]}: {prob:.4f} ({prob*100:.2f}%)")

        # Visualizar probabilidades
        plt.figure(figsize=(12, 6))

        # Gr√°fico de barras con todas las clases
        classes = [label_to_class[i] for i in range(len(label_to_class))]
        probs = predictions[0]
        colors = ['green' if i == pred_idx else 'lightblue' for i in range(len(probs))]

        bars = plt.bar(classes, probs, color=colors, edgecolor='navy', alpha=0.7)
        plt.xlabel('Clase')
        plt.ylabel('Probabilidad')
        plt.title('Probabilidades de predicci√≥n por clase')
        plt.ylim(0, 1)
        plt.grid(axis='y', alpha=0.3)

        # A√±adir valores en las barras
        for bar, prob in zip(bars, probs):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{prob:.3f}', ha='center', va='bottom', fontsize=10)

        plt.tight_layout()
        plt.show()

        # Mostrar activaciones si se solicita
        if mostrar_activaciones:
            print("\nüîç Visualizando activaciones de capas convolucionales...")
            try:
                visualizar_activaciones(model, img_input, idx_imagen=0)
            except Exception as e:
                print(f"Error al mostrar activaciones: {e}")

        return pred_class, confidence, predictions[0]

    except Exception as e:
        print(f"‚ùå Error al predecir la imagen: {e}")
        return None, None, None

# Funci√≥n auxiliar para predicci√≥n masiva
def predecir_directorio(directorio_path, model, label_to_class, target_size=(64, 64)):
    """Predice todas las im√°genes en un directorio"""
    extensiones = ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']
    imagenes = []
    for ext in extensiones:
        imagenes.extend(glob.glob(os.path.join(directorio_path, ext)))

    if not imagenes:
        print(f"No se encontraron im√°genes en {directorio_path}")
        return

    print(f"üîç Prediciendo {len(imagenes)} im√°genes en {directorio_path}")

    resultados = []
    for img_path in imagenes:
        pred_class, confidence, probs = predecir_imagen_cnn(
            img_path, model, label_to_class, target_size, mostrar_activaciones=False
        )
        resultados.append({
            'archivo': os.path.basename(img_path),
            'prediccion': pred_class,
            'confianza': confidence
        })

    # Mostrar resumen
    df_resultados = pd.DataFrame(resultados)
    print("\nüìã Resumen de predicciones:")
    print(df_resultados.groupby('prediccion').agg({
        'confianza': ['count', 'mean', 'min', 'max']
    }).round(4))

    return df_resultados

# Ejemplo de uso (descomenta y ajusta la ruta cuando quieras usar)
# pred_class, confidence, probs = predecir_imagen_cnn(
#     "ruta/a/una/imagen.png",
#     model,
#     label_to_class,
#     mostrar_activaciones=True,
#     aplicar_ajuste_contraste_camara=True # Ejemplo para foto de c√°mara
# )

"""## Testeo con Fotos de C√°mara

Esta secci√≥n permite probar el modelo con im√°genes nuevas, por ejemplo, fotos tomadas con una c√°mara.

### üì∏ Preparaci√≥n de las im√°genes de prueba:

1.  Crea una carpeta llamada `camera_test_data` en el mismo directorio que este notebook (`PC2/camera_test_data/`).
2.  Coloca las im√°genes que deseas probar en esta carpeta. Pueden ser formatos PNG o JPG.
3.  Las im√°genes ser√°n preprocesadas (incluyendo el ajuste de contraste opcional) para que coincidan con el formato esperado por el modelo.

El siguiente c√≥digo cargar√° las im√°genes de esta carpeta y realizar√° predicciones.
"""

# Cargar el modelo si no est√° cargado (o recargarlo para asegurar que es el mejor)
print("Cargando el mejor modelo entrenado (mejor_modelo.h5) para testeo con fotos de c√°mara...")
try:
    model_cam_test = keras.models.load_model('mejor_modelo.h5')
    print("Modelo cargado exitosamente para testeo con fotos de c√°mara.")
except Exception as e:
    print(f"Error al cargar el modelo: {e}. Aseg√∫rate de que el modelo 'mejor_modelo.h5' existe.")
    model_cam_test = None # Para evitar errores si la carga falla

if model_cam_test:
    # Ruta a la carpeta con im√°genes de prueba de c√°mara
    ruta_fotos_camara = './camera_test_data/' # Ajusta si es necesario

    if not os.path.exists(ruta_fotos_camara):
        print(f"ADVERTENCIA: La carpeta {ruta_fotos_camara} no existe. Por favor, cr√©ala y a√±ade im√°genes.")
    else:
        extensiones_camara = ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']
        imagenes_camara = []
        for ext in extensiones_camara:
            imagenes_camara.extend(glob.glob(os.path.join(ruta_fotos_camara, ext)))

        if not imagenes_camara:
            print(f"No se encontraron im√°genes en la carpeta: {ruta_fotos_camara}")
        else:
            print(f"\nüîç Probando {len(imagenes_camara)} im√°genes de la carpeta '{ruta_fotos_camara}':")
            for img_path_cam in imagenes_camara:
                print(f"\n--- Procesando imagen: {img_path_cam} ---")
                pred_class_cam, confidence_cam, probs_cam = predecir_imagen_cnn(
                    img_path_cam,
                    model_cam_test,
                    label_to_class,
                    target_size=input_shape[:2], # Usar el target_size del entrenamiento
                    mostrar_activaciones=False, # Puedes ponerlo a True para una imagen espec√≠fica
                    aplicar_ajuste_contraste_camara=True # Aplicar ajuste de contraste
                )
                if pred_class_cam:
                    print(f"Predicci√≥n para {os.path.basename(img_path_cam)}: {pred_class_cam} (Confianza: {confidence_cam:.2f})")
else:
    print("No se pudo cargar el modelo. Testeo con fotos de c√°mara omitido.")

# Guardar el modelo CNN completo
def guardar_modelo_cnn(model, history, label_to_class,
                      nombre_base='modelo_cnn_caracteres'):
    """Guarda el modelo CNN y toda la informaci√≥n asociada"""

    # Guardar modelo en formato TensorFlow
    ruta_modelo = f"{nombre_base}.h5"
    model.save(ruta_modelo)
    print(f"‚úÖ Modelo guardado en: {ruta_modelo}")

    # Guardar informaci√≥n del modelo
    info_modelo = {
        'arquitectura': arquitectura_elegida,
        'clases': clases,
        'label_to_class': label_to_class,
        'num_classes': num_classes,
        'input_shape': input_shape,
        'test_accuracy': test_accuracy,
        'test_loss': test_loss,
        'total_params': model.count_params(),
        'fecha_entrenamiento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
        'epochs_entrenados': len(history.history['accuracy']),
        'mejor_val_accuracy': max(history.history['val_accuracy']),
        'arquitectura_completa': model.to_json()
    }

    ruta_info = f"{nombre_base}_info.pkl"
    joblib.dump(info_modelo, ruta_info)
    print(f"‚úÖ Informaci√≥n del modelo guardada en: {ruta_info}")

    # Guardar historial de entrenamiento
    ruta_history = f"{nombre_base}_history.pkl"
    joblib.dump(history.history, ruta_history)
    print(f"‚úÖ Historial de entrenamiento guardado en: {ruta_history}")

    # Guardar pesos del modelo (formato m√°s ligero)
    ruta_pesos = f"{nombre_base}_pesos.h5"
    model.save_weights(ruta_pesos)
    print(f"‚úÖ Pesos del modelo guardados en: {ruta_pesos}")

    return ruta_modelo, ruta_info, ruta_history, ruta_pesos

def cargar_modelo_cnn(ruta_modelo='modelo_cnn_caracteres.h5',
                     ruta_info='modelo_cnn_caracteres_info.pkl'):
    """Carga el modelo CNN desde disco"""

    try:
        # Cargar modelo
        model = keras.models.load_model(ruta_modelo)
        print(f"‚úÖ Modelo cargado desde: {ruta_modelo}")

        # Cargar informaci√≥n adicional
        if os.path.exists(ruta_info):
            info_modelo = joblib.load(ruta_info)
            print(f"‚úÖ Informaci√≥n del modelo cargada desde: {ruta_info}")

            print(f"\nüìä Informaci√≥n del modelo:")
            print(f"Arquitectura: {info_modelo.get('arquitectura', 'No especificada')}")
            print(f"Clases: {info_modelo.get('clases', [])}")
            print(f"Precisi√≥n en prueba: {info_modelo.get('test_accuracy', 'N/A'):.4f}")
            print(f"Fecha de entrenamiento: {info_modelo.get('fecha_entrenamiento', 'N/A')}")
            print(f"√âpocas entrenadas: {info_modelo.get('epochs_entrenados', 'N/A')}")
            print(f"Par√°metros totales: {info_modelo.get('total_params', 'N/A'):,}")

            return model, info_modelo
        else:
            print(f"‚ö†Ô∏è No se encontr√≥ archivo de informaci√≥n en: {ruta_info}")
            return model, None

    except Exception as e:
        print(f"‚ùå Error al cargar el modelo: {e}")
        return None, None

# Guardar el modelo actual
print("üíæ Guardando modelo CNN...")
rutas = guardar_modelo_cnn(model, history, label_to_class)

# Crear resumen del entrenamiento
resumen_df = pd.DataFrame({
    'M√©trica': ['Precisi√≥n entrenamiento', 'Precisi√≥n validaci√≥n', 'Precisi√≥n prueba',
                'P√©rdida entrenamiento', 'P√©rdida validaci√≥n', 'P√©rdida prueba',
                'Par√°metros totales', '√âpocas entrenadas'],
    'Valor': [
        f"{history.history['accuracy'][-1]:.4f}",
        f"{history.history['val_accuracy'][-1]:.4f}",
        f"{test_accuracy:.4f}",
        f"{history.history['loss'][-1]:.4f}",
        f"{history.history['val_loss'][-1]:.4f}",
        f"{test_loss:.4f}",
        f"{model.count_params():,}",
        f"{len(history.history['accuracy'])}"
    ]
})

print(f"\nüìã Resumen del modelo entrenado:")
print(resumen_df.to_string(index=False))

# Ejemplo de c√≥mo cargar el modelo (descomenta cuando sea necesario)
# modelo_cargado, info = cargar_modelo_cnn()

"""## 11. Conclusiones

En este notebook, hemos desarrollado un sistema completo de reconocimiento de caracteres escritos a mano utilizando Redes Neuronales Convolucionales (CNN) que incluye:

### üéØ Caracter√≠sticas principales desarrolladas:

1. **üìÅ Sistema de carga de datos robusto**:
   - Carga autom√°tica desde carpetas organizadas por clase
   - Preprocesamiento optimizado para CNN
   - Guardado/carga eficiente con archivos .npy

2. **üèóÔ∏è Arquitectura CNN moderna**:
   - M√∫ltiples opciones de arquitectura (b√°sica, intermedia, avanzada)
   - Capas de BatchNormalization y Dropout para estabilidad
   - Configuraci√≥n optimizada de hiperpar√°metros

3. **üìä An√°lisis post-entrenamiento exhaustivo**:
   - Visualizaci√≥n de errores con an√°lisis de confianza
   - Activaciones de capas convolucionales
   - M√©tricas detalladas por clase
   - Distribuci√≥n de confianza de predicciones

4. **üîç Sistema de predicci√≥n completo**:
   - Predicci√≥n de im√°genes individuales
   - Procesamiento masivo de directorios
   - Visualizaci√≥n de activaciones en tiempo real

### üìà Ventajas sobre m√©todos tradicionales:

- **Mayor precisi√≥n**: Las CNN son superiores para reconocimiento de im√°genes
- **Robustez**: Mejor manejo de variaciones en escritura y calidad de imagen
- **Escalabilidad**: F√°cil extensi√≥n a m√°s clases de caracteres
- **Interpretabilidad**: Visualizaci√≥n de qu√© aprende el modelo

### üîß Posibles mejoras futuras:

1. **Data Augmentation**: Rotar, escalar y deformar im√°genes para mayor robustez
2. **Transfer Learning**: Usar modelos preentrenados como punto de partida
3. **Ensemble Methods**: Combinar m√∫ltiples modelos para mayor precisi√≥n
4. **Optimizaci√≥n de hiperpar√°metros**: Grid search o Bayesian optimization
5. **Arquitecturas m√°s avanzadas**: ResNet, DenseNet, o Vision Transformers
6. **Regularizaci√≥n avanzada**: Label smoothing, mixup, cutmix

### üí° Aplicaciones pr√°cticas:

- Digitalizaci√≥n de documentos hist√≥ricos
- Reconocimiento de formularios manuscritos
- Sistemas de captura de firmas
- Aplicaciones educativas de escritura
- Asistentes digitales para personas con discapacidades

Este sistema proporciona una base s√≥lida para aplicaciones de reconocimiento de caracteres en el mundo real, con herramientas completas para an√°lisis, debugging y mejora continua del modelo.
"""