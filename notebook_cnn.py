# -*- coding: utf-8 -*-
"""Copia de PC2_GRAFICA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qC7mk6rpUJHW7Ev2huFFBYEl-ZX9dahn

# PC2 GRÁFICA - Sistema de Reconocimiento de Caracteres con CNN

Este notebook demuestra cómo entrenar una Red Neuronal Convolucional (CNN) para reconocer caracteres escritos a mano. El sistema utiliza arquitecturas de deep learning modernas para lograr alta precisión en la clasificación de caracteres.

## Contenido
1. [Configuración del entorno](#1.-Configuración-del-entorno)
2. [Estructura de datos y carga](#2.-Estructura-de-datos-y-carga)
3. [Carga y exploración de datos](#3.-Carga-y-exploración-de-datos)
4. [Preprocesamiento de imágenes](#4.-Preprocesamiento-de-imágenes)
5. [Arquitectura CNN](#5.-Arquitectura-CNN)
6. [Entrenamiento del modelo](#6.-Entrenamiento-del-modelo)
7. [Evaluación del modelo](#7.-Evaluación-del-modelo)
8. [Análisis post-entrenamiento](#8.-Análisis-post-entrenamiento)
9. [Predicciones con nuevas imágenes](#9.-Predicciones-con-nuevas-imágenes)
10. [Exportación del modelo](#10.-Exportación-del-modelo)
11. [Conclusiones](#11.-Conclusiones)

## 1. Configuración del entorno

Primero, importamos las bibliotecas necesarias para nuestro proyecto, incluyendo TensorFlow para las CNN.
"""

# Commented out IPython magic to ensure Python compatibility.
# Importación de bibliotecas necesarias
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import glob
from skimage import io, transform
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import pandas as pd
from sklearn.decomposition import PCA
from matplotlib import gridspec
import cv2

# TensorFlow y Keras para CNN
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Configuración para visualizaciones
# %matplotlib inline
plt.style.use('ggplot')
plt.rcParams['figure.figsize'] = (12, 8)
sns.set_theme(style="whitegrid")

# Configuración de TensorFlow
print(f"TensorFlow versión: {tf.__version__}")
print(f"GPU disponible: {tf.test.is_gpu_available()}")
if tf.test.is_gpu_available():
    print(f"Dispositivos GPU: {tf.config.list_physical_devices('GPU')}")

"""// ...existing code...
## 2. Estructura de datos y carga

### 💾 Archivos de datos requeridos:

Para que el sistema funcione correctamente, necesitas tener los siguientes archivos `.npy` en la carpeta `data/` (o la ruta que especifiques):

```
PC2/
├── data/                    # Carpeta principal de datos
│   ├── X.npy               # Array NumPy con los datos de las imágenes (N, H, W, C) o (N, H*W)
│   ├── Y.npy               # Array NumPy con las etiquetas numéricas (N,)
│   └── clases.npy          # (Opcional) Array NumPy con los nombres de las clases.
│                           # Si no se provee, las clases se inferirán de Y.npy.
└── PC2_GRAFICA.ipynb       # Este notebook
```

### 🎯 Requisitos de los archivos `.npy`:

1.  **`X.npy`**:
    *   Debe ser un array NumPy.
    *   Puede tener forma `(N, H, W, C)` donde `N` es el número de imágenes, `H` la altura, `W` el ancho, y `C` el número de canales (usualmente 1 para escala de grises).
    *   Alternativamente, puede tener forma `(N, F)` donde `F` es `H*W*C` (datos aplanados). La función intentará remodelarlo.
    *   Se espera que los valores de píxeles estén en el rango `[0, 255]` o ya normalizados a `[0, 1]`. La función aplicará normalización si detecta valores mayores a 1.
2.  **`Y.npy`**:
    *   Debe ser un array NumPy de forma `(N,)` conteniendo las etiquetas numéricas (enteros) para cada imagen en `X.npy`.
3.  **`clases.npy`** (Opcional):
    *   Si se proporciona, debe ser un array NumPy conteniendo los nombres de las clases en el orden correspondiente a las etiquetas numéricas en `Y.npy`.
    *   Si no se proporciona, las clases se nombrarán como "Clase 0", "Clase 1", etc., basado en las etiquetas únicas en `Y.npy`.

### 📋 Instrucciones de preparación:

1.  Crea la carpeta `data` en el mismo directorio que este notebook (o la ruta que desees usar).
2.  Coloca tus archivos `X.npy` e `Y.npy` (y opcionalmente `clases.npy`) en esta carpeta.
3.  Asegúrate de que `X.npy` e `Y.npy` sean consistentes (mismo número de muestras `N`).
// ...existing code...
"""

# ...existing code...
def cargar_datos_cnn(ruta_base='./data/', target_shape_hint=(64, 64, 1)):
    """
    Carga los datos desde archivos X.npy e Y.npy.
    Intenta remodelar X si es necesario y normaliza los valores de píxeles.

    Args:
        ruta_base: Ruta base donde se encuentran los archivos .npy.
        target_shape_hint: Tupla (H, W, C) para ayudar a remodelar X si está aplanado
                           y para verificar la forma final.

    Returns:
        X: Imágenes normalizadas para CNN (N, H, W, C)
        y: Etiquetas numéricas (N,)
        clases: Lista de clases únicas (nombres)
        label_to_class: Diccionario de mapeo de etiquetas numéricas a nombres de clase
    """
    ruta_X = os.path.join(ruta_base, 'X.npy')
    ruta_y = os.path.join(ruta_base, 'Y.npy')
    ruta_clases_npy = os.path.join(ruta_base, 'clases.npy')

    if not os.path.exists(ruta_X) or not os.path.exists(ruta_y):
        raise FileNotFoundError(
            f"No se encontraron 'X.npy' o 'Y.npy' en {ruta_base}. "
            "Por favor, asegúrate de que los archivos existen."
        )

    print(f"Cargando datos desde {ruta_X} y {ruta_y}...")
    X = np.load(ruta_X)
    y = np.load(ruta_y)

    print(f"Forma original de X: {X.shape}")
    print(f"Forma original de y: {y.shape}")

    # Validar consistencia
    if X.shape[0] != y.shape[0]:
        raise ValueError(
            f"Inconsistencia en el número de muestras: X tiene {X.shape[0]} y Y tiene {y.shape[0]}"
        )

    # Remodelar X si es necesario
    N = X.shape[0]
    H, W, C = target_shape_hint

    if X.ndim == 2: # (N, Features_aplanadas)
        expected_features = H * W * C
        if X.shape[1] == H * W: # Asumiendo C=1 si no se especifica en target_shape_hint o es implícito
             if C == 1 and target_shape_hint[2] !=1: # Si el hint tenia C > 1 pero X.shape[1] solo cubre H*W
                 print(f"Advertencia: X.shape[1] ({X.shape[1]}) coincide con H*W ({H*W}). Asumiendo C=1.")
             X = X.reshape(N, H, W, 1) # Asumir C=1 si solo H*W coincide
        elif X.shape[1] == expected_features:
            X = X.reshape(N, H, W, C)
        else:
            raise ValueError(
                f"X está aplanado con {X.shape[1]} características, "
                f"pero se esperaban {expected_features} (para {H}x{W}x{C}) o {H*W} (para {H}x{W}x1)."
                "Verifica target_shape_hint."
            )
        print(f"X remodelado a: {X.shape}")
    elif X.ndim == 3: # (N, H, W) -> Añadir canal
        X = np.expand_dims(X, axis=-1)
        print(f"X expandido a: {X.shape}")
    elif X.ndim == 4: # (N, H, W, C)
        print("X ya tiene 4 dimensiones, no se requiere remodelación.")
    else:
        raise ValueError(f"Forma de X no soportada: {X.shape}. Se espera 2D, 3D o 4D.")

    # Verificar forma final con target_shape_hint
    if X.shape[1:] != target_shape_hint:
         print(
            f"Advertencia: La forma de X procesado {X.shape[1:]} no coincide exactamente con target_shape_hint {target_shape_hint}."
            "Continuando, pero revisa tus datos y el hint."
        )


    # Normalizar X a [0, 1] si no lo está ya
    if X.max() > 1.0:
        print("Normalizando X a [0, 1] (dividiendo por 255.0)...")
        X = X.astype(np.float32) / 255.0
    else:
        print("X parece estar ya normalizado (max <= 1.0).")

    X = X.astype(np.float32) # Asegurar float32 para TensorFlow

    # Cargar o generar nombres de clases
    if os.path.exists(ruta_clases_npy):
        clases_nombres = np.load(ruta_clases_npy, allow_pickle=True)
        print(f"Nombres de clases cargados desde {ruta_clases_npy}: {clases_nombres}")
        # Validar que el número de clases coincida con las etiquetas
        unique_labels = np.unique(y)
        if len(clases_nombres) < len(unique_labels):
            raise ValueError(
                f"El archivo 'clases.npy' tiene {len(clases_nombres)} nombres, "
                f"pero se encontraron {len(unique_labels)} etiquetas únicas en Y.npy."
            )
        # Tomar solo los nombres necesarios si clases_nombres es más largo (podría tener nombres para etiquetas no presentes)
        clases_nombres = [clases_nombres[i] for i in sorted(unique_labels)]

    else:
        print("No se encontró 'clases.npy'. Generando nombres de clase por defecto.")
        unique_labels = sorted(list(np.unique(y)))
        clases_nombres = [f"Clase {label}" for label in unique_labels]

    label_to_class = {i: nombre for i, nombre in enumerate(clases_nombres)}
    # Asegurar que 'y' use índices de 0 a num_clases-1 si es necesario
    # Esto es importante si las etiquetas en Y.npy no son secuenciales desde 0
    map_original_to_sequential = {original_label: sequential_label for sequential_label, original_label in enumerate(sorted(np.unique(y)))}
    y_sequential = np.array([map_original_to_sequential[val] for val in y])


    print(f"Datos cargados: {X.shape[0]} imágenes.")
    print(f"Número de clases detectadas/cargadas: {len(clases_nombres)}")
    print(f"Forma final de X: {X.shape} (N, H, W, C)")
    print(f"Forma final de y: {y_sequential.shape}")

    return X, y_sequential, clases_nombres, label_to_class
#...existing code...

"""## 3. Carga y exploración de datos

Cargamos los datos y exploramos su estructura con visualizaciones específicas para CNN.
"""

# ...existing code...
# Cargamos los datos desde .npy
# Define el target_shape_hint (H, W, C) esperado para tus imágenes después de la carga y remodelación.
# Por ejemplo, si tus imágenes son 64x64 en escala de grises:
EXPECTED_IMG_HEIGHT = 64
EXPECTED_IMG_WIDTH = 64
EXPECTED_IMG_CHANNELS = 1
target_shape_hint = (EXPECTED_IMG_HEIGHT, EXPECTED_IMG_WIDTH, EXPECTED_IMG_CHANNELS)

try:
    X, y, clases, label_to_class = cargar_datos_cnn(ruta_base='./data/', target_shape_hint=target_shape_hint)

    # Información básica sobre el conjunto de datos
    print(f"\nInformación del dataset:")
    print(f"Forma de X: {X.shape}")
    print(f"Tipo de datos de X: {X.dtype}")
    print(f"Rango de valores en X: [{X.min():.3f}, {X.max():.3f}]")
    print(f"Forma de y: {y.shape}")
    print(f"Tipo de datos de y: {y.dtype}")
    print(f"Clases encontradas/definidas: {clases}")
    print(f"Mapeo de etiquetas: {label_to_class}")

    # Distribución de clases
    unique_labels_in_y, counts = np.unique(y, return_counts=True)
    distribucion = {label_to_class[label]: count for label, count in zip(unique_labels_in_y, counts)}

    print("\nDistribución de clases:")
    for clase_nombre, cantidad in distribucion.items():
        print(f"  {clase_nombre}: {cantidad} imágenes")

    # Visualización de la distribución
    plt.figure(figsize=(10, 6))
    class_names_for_plot = [label_to_class[i] for i in unique_labels_in_y] # Usar los nombres de clase correctos
    plt.bar(class_names_for_plot, counts, color='skyblue', edgecolor='navy', alpha=0.7)
    plt.xlabel('Clases')
    plt.ylabel('Número de imágenes')
    plt.title('Distribución de imágenes por clase')
    plt.xticks(rotation=45, ha="right") # Rotar etiquetas si son muchas
    plt.grid(axis='y', alpha=0.3)
    for i, count in enumerate(counts):
        plt.text(i, count + max(counts)*0.01, str(count), ha='center', va='bottom') # Ajustar posición del texto
    plt.tight_layout() # Ajustar layout para evitar superposiciones
    plt.show()

except FileNotFoundError as e:
    print(e)
    print("Por favor, crea los archivos X.npy e Y.npy en la carpeta './data/' o especifica la ruta correcta.")
    # Detener la ejecución o manejar el error como prefieras
    X, y, clases, label_to_class = (None, None, None, None) # Para evitar errores en celdas posteriores si no se cargan
except ValueError as e:
    print(f"Error al procesar los datos: {e}")
    X, y, clases, label_to_class = (None, None, None, None)

# ... El resto de la celda puede continuar, pero asegúrate de que X, y, etc., no sean None
# ...existing code...

def visualizar_ejemplos_cnn(X, y, clases, label_to_class, n_ejemplos=6):
    """Visualiza ejemplos de cada clase optimizado para datos de CNN"""
    n_clases = len(clases)
    fig, axes = plt.subplots(n_clases, n_ejemplos, figsize=(n_ejemplos*2, n_clases*2.5))

    if n_clases == 1:
        axes = axes.reshape(1, -1)

    for i, clase in enumerate(clases):
        # Obtener índices de esta clase
        indices = np.where(y == i)[0]
        # Seleccionar aleatoriamente n_ejemplos
        seleccionados = np.random.choice(indices, min(n_ejemplos, len(indices)), replace=False)

        for j, idx in enumerate(seleccionados):
            ax = axes[i, j]
            # Mostrar imagen (squeeze para remover dimensión de canal si es necesario)
            img_display = X[idx].squeeze()
            ax.imshow(img_display, cmap='gray')
            ax.set_title(f'{clase} ({idx})', fontsize=10)
            ax.axis('off')

            # Agregar información de la imagen
            ax.text(0.02, 0.98, f'Shape: {X[idx].shape}\nMin: {X[idx].min():.2f}\nMax: {X[idx].max():.2f}',
                   transform=ax.transAxes, fontsize=8, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

    plt.tight_layout()
    plt.suptitle('Ejemplos de imágenes por clase (Datos preparados para CNN)', y=1.02, fontsize=16)
    plt.show()

# Visualizar ejemplos
visualizar_ejemplos_cnn(X, y, clases, label_to_class)

"""## 4. Preprocesamiento de imágenes

Preparamos los datos específicamente para entrenamiento con CNN, incluyendo división de conjuntos y codificación categórica.
"""

# Convertir etiquetas a formato categórico (one-hot encoding)
num_classes = len(clases)
y_categorical = to_categorical(y, num_classes)

print(f"Forma original de y: {y.shape}")
print(f"Forma categórica de y: {y_categorical.shape}")
print(f"Ejemplo de codificación:")
for i in range(min(3, len(y))):
    print(f"  Clase {label_to_class[y[i]]} -> {y[i]} -> {y_categorical[i]}")

# Dividir en conjuntos de entrenamiento, validación y prueba
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y_categorical, test_size=0.2, random_state=42, stratify=y
)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp.argmax(axis=1)
)

print(f"\nDivisión de datos:")
print(f"Entrenamiento: {X_train.shape[0]} imágenes ({X_train.shape[0]/len(X)*100:.1f}%)")
print(f"Validación: {X_val.shape[0]} imágenes ({X_val.shape[0]/len(X)*100:.1f}%)")
print(f"Prueba: {X_test.shape[0]} imágenes ({X_test.shape[0]/len(X)*100:.1f}%)")

# Verificar las formas finales
print(f"\nFormas finales:")
print(f"X_train: {X_train.shape}")
print(f"X_val: {X_val.shape}")
print(f"X_test: {X_test.shape}")
print(f"y_train: {y_train.shape}")
print(f"y_val: {y_val.shape}")
print(f"y_test: {y_test.shape}")

"""## 5. Arquitectura CNN

Definimos la arquitectura de la Red Neuronal Convolucional con capas optimizadas para reconocimiento de caracteres.

### 🏗️ Arquitectura propuesta:
- **Capas Convolucionales**: Para extracción de características
- **Pooling**: Para reducción de dimensionalidad
- **Batch Normalization**: Para estabilidad del entrenamiento
- **Dropout**: Para prevenir overfitting
- **Capas densas**: Para clasificación final
"""

def crear_modelo_cnn(input_shape, num_classes, arquitectura='basica'):
    """
    Crea un modelo CNN para reconocimiento de caracteres

    Args:
        input_shape: Forma de entrada (height, width, channels)
        num_classes: Número de clases a clasificar
        arquitectura: 'basica', 'intermedia' o 'avanzada'

    Returns:
        model: Modelo CNN compilado
    """

    if arquitectura == 'basica':
        model = Sequential([
            # Primera capa convolucional
            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
            BatchNormalization(),
            MaxPooling2D((2, 2)),

            # Segunda capa convolucional
            Conv2D(64, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),

            # Tercera capa convolucional
            Conv2D(128, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),

            # Aplanar para capas densas
            Flatten(),

            # Capas densas
            Dense(128, activation='relu'),
            Dropout(0.5),
            Dense(64, activation='relu'),
            Dropout(0.3),
            Dense(num_classes, activation='softmax')
        ])

    elif arquitectura == 'intermedia':
        model = Sequential([
            # Primer bloque convolucional
            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
            Conv2D(32, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.25),

            # Segundo bloque convolucional
            Conv2D(64, (3, 3), activation='relu'),
            Conv2D(64, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.25),

            # Tercer bloque convolucional
            Conv2D(128, (3, 3), activation='relu'),
            Conv2D(128, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.25),

            # Capas densas
            Flatten(),
            Dense(256, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(128, activation='relu'),
            Dropout(0.3),
            Dense(num_classes, activation='softmax')
        ])

    else:  # avanzada
        model = Sequential([
            # Primer bloque
            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),

            # Segundo bloque
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),

            # Tercer bloque
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),

            # Cuarto bloque
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),

            # Capas densas
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(256, activation='relu'),
            BatchNormalization(),
            Dropout(0.4),
            Dense(128, activation='relu'),
            Dropout(0.3),
            Dense(num_classes, activation='softmax')
        ])

    return model

# Crear el modelo
input_shape = X_train.shape[1:]  # (height, width, channels)
print(f"Forma de entrada: {input_shape}")
print(f"Número de clases: {num_classes}")

# Seleccionar arquitectura (puedes cambiar entre 'basica', 'intermedia', 'avanzada')
arquitectura_elegida = 'intermedia'
model = crear_modelo_cnn(input_shape, num_classes, arquitectura_elegida)

# Compilar el modelo
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Mostrar resumen del modelo
print(f"\n🏗️ Arquitectura seleccionada: {arquitectura_elegida}")
print("="*50)
model.summary()

# Visualizar la arquitectura
try:
    tf.keras.utils.plot_model(
        model,
        to_file='modelo_arquitectura.png',
        show_shapes=True,
        show_layer_names=True,
        rankdir='TB',
        dpi=150
    )
    print("\n📊 Diagrama de arquitectura guardado como 'modelo_arquitectura.png'")
except:
    print("\n⚠️ No se pudo generar el diagrama de arquitectura (requiere graphviz)")

"""## 6. Entrenamiento del modelo

Entrenamos la CNN con callbacks para optimizar el proceso de entrenamiento.
"""

# Configurar callbacks para un entrenamiento eficiente
callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    ),
    ModelCheckpoint(
        filepath='mejor_modelo.h5',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )
]

# Configuración de entrenamiento
EPOCHS = 50
BATCH_SIZE = 32

print(f"🚀 Iniciando entrenamiento:")
print(f"Épocas máximas: {EPOCHS}")
print(f"Tamaño de batch: {BATCH_SIZE}")
print(f"Callbacks configurados: {len(callbacks)}")
print("="*50)

# Entrenar el modelo
history = model.fit(
    X_train, y_train,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=(X_val, y_val),
    callbacks=callbacks,
    verbose=1
)

print("\n✅ Entrenamiento completado!")

# Visualizar las curvas de entrenamiento
def plot_training_history(history):
    """Visualiza las métricas de entrenamiento"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    # Accuracy
    ax1.plot(history.history['accuracy'], label='Entrenamiento', color='blue')
    ax1.plot(history.history['val_accuracy'], label='Validación', color='orange')
    ax1.set_title('Precisión del Modelo')
    ax1.set_xlabel('Época')
    ax1.set_ylabel('Precisión')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Loss
    ax2.plot(history.history['loss'], label='Entrenamiento', color='blue')
    ax2.plot(history.history['val_loss'], label='Validación', color='orange')
    ax2.set_title('Pérdida del Modelo')
    ax2.set_xlabel('Época')
    ax2.set_ylabel('Pérdida')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Mostrar métricas finales
    final_train_acc = history.history['accuracy'][-1]
    final_val_acc = history.history['val_accuracy'][-1]
    final_train_loss = history.history['loss'][-1]
    final_val_loss = history.history['val_loss'][-1]

    print(f"\n📊 Métricas finales:")
    print(f"Precisión entrenamiento: {final_train_acc:.4f}")
    print(f"Precisión validación: {final_val_acc:.4f}")
    print(f"Pérdida entrenamiento: {final_train_loss:.4f}")
    print(f"Pérdida validación: {final_val_loss:.4f}")

    # Detectar overfitting
    if final_train_acc - final_val_acc > 0.1:
        print("⚠️ Posible overfitting detectado (diferencia > 10%)")
    else:
        print("✅ Buen balance entre entrenamiento y validación")

plot_training_history(history)

"""## 7. Evaluación del modelo

Evaluamos el rendimiento del modelo CNN en el conjunto de prueba.
"""

# Cargar el mejor modelo guardado durante el entrenamiento
print("Cargando el mejor modelo entrenado (mejor_modelo.h5)...")
model = keras.models.load_model('mejor_modelo.h5')
print("Modelo cargado exitosamente.")

# Evaluar en conjunto de prueba
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"📈 Resultados en conjunto de prueba:")
print(f"Precisión: {test_accuracy:.4f}")
print(f"Pérdida: {test_loss:.4f}")

# Predicciones en conjunto de prueba
y_pred_proba = model.predict(X_test)
y_pred = np.argmax(y_pred_proba, axis=1)
y_test_labels = np.argmax(y_test, axis=1)

# Reporte de clasificación
print("\n📋 Informe de clasificación:")
print(classification_report(y_test_labels, y_pred, target_names=clases))

# Matriz de confusión
cm = confusion_matrix(y_test_labels, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=clases, yticklabels=clases)
plt.xlabel('Predicción')
plt.ylabel('Valor real')
plt.title('Matriz de confusión - Conjunto de prueba', fontsize=16)
plt.tight_layout()
plt.show()

# Calcular métricas adicionales por clase
from sklearn.metrics import precision_recall_fscore_support

precision, recall, f1, support = precision_recall_fscore_support(
    y_test_labels, y_pred, average=None
)

metrics_df = pd.DataFrame({
    'Clase': clases,
    'Precisión': precision,
    'Recall': recall,
    'F1-Score': f1,
    'Soporte': support
})

print("\n📊 Métricas detalladas por clase:")
print(metrics_df.round(4))

"""## 8. Análisis post-entrenamiento

Realizamos un análisis exhaustivo de los errores del modelo y visualizamos las activaciones de las capas convolucionales.
"""

# Análisis detallado de errores
def analizar_errores_cnn(X_test, y_test, y_pred, y_pred_proba, label_to_class, max_errores=15):
    """Análisis comprehensivo de errores del modelo CNN"""

    # Encontrar índices de errores
    y_test_labels = np.argmax(y_test, axis=1)
    errores_idx = np.where(y_test_labels != y_pred)[0]

    print(f"📊 Análisis de errores:")
    print(f"Total de errores: {len(errores_idx)} de {len(y_test)} ({len(errores_idx)/len(y_test)*100:.2f}%)")

    if len(errores_idx) == 0:
        print("🎉 ¡No hay errores para analizar!")
        return

    # Analizar tipos de errores más comunes
    errores_df = pd.DataFrame({
        'Real': [label_to_class[label] for label in y_test_labels[errores_idx]],
        'Predicho': [label_to_class[label] for label in y_pred[errores_idx]],
        'Confianza': np.max(y_pred_proba[errores_idx], axis=1)
    })

    print("\n🔍 Tipos de errores más comunes:")
    error_counts = errores_df.groupby(['Real', 'Predicho']).size().reset_index(name='Cantidad')
    error_counts = error_counts.sort_values('Cantidad', ascending=False)
    print(error_counts.head(10))

    # Visualizar errores con menor confianza (más inciertos)
    errores_ordenados = errores_idx[np.argsort(np.max(y_pred_proba[errores_idx], axis=1))]

    n_mostrar = min(max_errores, len(errores_ordenados))
    n_cols = 5
    n_rows = (n_mostrar + n_cols - 1) // n_cols

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))
    axes = axes.flatten() if n_rows > 1 else [axes] if n_mostrar == 1 else axes

    for i in range(n_mostrar):
        idx = errores_ordenados[i]
        img = X_test[idx].squeeze()
        real = y_test_labels[idx]
        pred = y_pred[idx]
        confianza = np.max(y_pred_proba[idx])

        ax = axes[i]
        ax.imshow(img, cmap='gray')
        ax.set_title(f'Real: {label_to_class[real]}\nPred: {label_to_class[pred]}\nConf: {confianza:.3f}',
                    fontsize=10, color='red')
        ax.axis('off')

        # Mostrar top 3 predicciones
        top_3_idx = np.argsort(y_pred_proba[idx])[-3:][::-1]
        prob_text = '\n'.join([f'{label_to_class[j]}: {y_pred_proba[idx][j]:.3f}'
                              for j in top_3_idx])
        ax.text(0.02, 0.02, prob_text, transform=ax.transAxes, fontsize=8,
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),
                verticalalignment='bottom')

    # Ocultar ejes no utilizados
    for i in range(n_mostrar, len(axes)):
        axes[i].axis('off')

    plt.tight_layout()
    plt.suptitle('Errores con menor confianza (más inciertos)', y=1.02, fontsize=16)
    plt.show()

    return errores_df

# Ejecutar análisis de errores
errores_df = analizar_errores_cnn(X_test, y_test, y_pred, y_pred_proba, label_to_class)

# Visualización de activaciones de capas convolucionales
def visualizar_activaciones(model, X_test, idx_imagen=0, capas_conv=None):
    """Visualiza las activaciones de las capas convolucionales"""

    if capas_conv is None:
        # Obtener automáticamente las primeras capas convolucionales
        capas_conv = []
        for i, layer in enumerate(model.layers):
            if isinstance(layer, Conv2D):
                capas_conv.append(i)
            if len(capas_conv) >= 4:  # Limitar a las primeras 4 capas conv
                break

    if not capas_conv:
        print("No se encontraron capas convolucionales en el modelo")
        return

    # Crear modelo para extraer activaciones
    outputs = [model.layers[i].output for i in capas_conv]
    activation_model = keras.Model(inputs=model.input, outputs=outputs)

    # Obtener activaciones para una imagen
    img_input = np.expand_dims(X_test[idx_imagen], axis=0)
    activations = activation_model.predict(img_input, verbose=0)

    # Visualizar imagen original
    plt.figure(figsize=(15, 2 + len(capas_conv) * 3))

    # Imagen original
    plt.subplot(len(capas_conv) + 1, 1, 1)
    plt.imshow(X_test[idx_imagen].squeeze(), cmap='gray')
    plt.title('Imagen Original')
    plt.axis('off')

    # Visualizar activaciones de cada capa
    for i, (capa_idx, activation) in enumerate(zip(capas_conv, activations)):
        layer_name = model.layers[capa_idx].name

        # Mostrar algunos filtros de la activación
        n_features = min(16, activation.shape[-1])  # Máximo 16 filtros
        n_cols = 8
        n_rows = (n_features + n_cols - 1) // n_cols

        plt.subplot(len(capas_conv) + 1, 1, i + 2)
        fig_temp, axes_temp = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 1.5))
        if n_rows == 1:
            axes_temp = axes_temp.reshape(1, -1)

        for j in range(n_features):
            row = j // n_cols
            col = j % n_cols
            axes_temp[row, col].imshow(activation[0, :, :, j], cmap='viridis')
            axes_temp[row, col].set_title(f'Filtro {j}', fontsize=8)
            axes_temp[row, col].axis('off')

        # Ocultar axes no utilizados
        for j in range(n_features, n_rows * n_cols):
            row = j // n_cols
            col = j % n_cols
            axes_temp[row, col].axis('off')

        plt.suptitle(f'Activaciones - {layer_name}', fontsize=12)
        plt.tight_layout()
        plt.show()

# Visualizar activaciones para una imagen de prueba
print("🔍 Visualización de activaciones de capas convolucionales:")
try:
    visualizar_activaciones(model, X_test, idx_imagen=0)
except Exception as e:
    print(f"Error al visualizar activaciones: {e}")

# Análisis de confianza de predicciones
def analizar_confianza_predicciones(y_pred_proba, y_test, y_pred, label_to_class):
    """Analiza la distribución de confianza de las predicciones"""

    y_test_labels = np.argmax(y_test, axis=1)
    confianzas = np.max(y_pred_proba, axis=1)
    correctas = (y_pred == y_test_labels)

    # Estadísticas de confianza
    print("📊 Análisis de confianza de predicciones:")
    print(f"Confianza promedio (correctas): {confianzas[correctas].mean():.4f}")
    print(f"Confianza promedio (incorrectas): {confianzas[~correctas].mean():.4f}")
    print(f"Confianza mínima: {confianzas.min():.4f}")
    print(f"Confianza máxima: {confianzas.max():.4f}")

    # Visualizar distribución de confianza
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))

    # Histograma de confianza
    ax1.hist(confianzas[correctas], bins=30, alpha=0.7, label='Correctas', color='green')
    ax1.hist(confianzas[~correctas], bins=30, alpha=0.7, label='Incorrectas', color='red')
    ax1.set_xlabel('Confianza')
    ax1.set_ylabel('Frecuencia')
    ax1.set_title('Distribución de Confianza')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Precisión por nivel de confianza
    bins = np.linspace(0, 1, 11)
    bin_centers = (bins[:-1] + bins[1:]) / 2
    accuracies = []

    for i in range(len(bins) - 1):
        mask = (confianzas >= bins[i]) & (confianzas < bins[i+1])
        if mask.sum() > 0:
            acc = correctas[mask].mean()
            accuracies.append(acc)
        else:
            accuracies.append(0)

    ax2.plot(bin_centers, accuracies, 'o-', linewidth=2, markersize=8)
    ax2.set_xlabel('Nivel de Confianza')
    ax2.set_ylabel('Precisión')
    ax2.set_title('Precisión vs Nivel de Confianza')
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(0, 1.05)

    # Matriz de confianza por clase
    confianza_por_clase = []
    for clase_idx in range(len(label_to_class)):
        mask = y_test_labels == clase_idx
        if mask.sum() > 0:
            confianza_por_clase.append(confianzas[mask].mean())
        else:
            confianza_por_clase.append(0)

    ax3.bar(range(len(label_to_class)), confianza_por_clase, color='skyblue', edgecolor='navy')
    ax3.set_xlabel('Clase')
    ax3.set_ylabel('Confianza Promedio')
    ax3.set_title('Confianza Promedio por Clase')
    ax3.set_xticks(range(len(label_to_class)))
    ax3.set_xticklabels([label_to_class[i] for i in range(len(label_to_class))])
    ax3.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.show()

    return confianzas, correctas

# Ejecutar análisis de confianza
confianzas, correctas = analizar_confianza_predicciones(y_pred_proba, y_test, y_pred, label_to_class)

"""## 9. Predicciones con nuevas imágenes

Creamos una función optimizada para hacer predicciones con nuevas imágenes usando el modelo CNN entrenado.
"""

def predecir_imagen_cnn(imagen_path, model, label_to_class, target_size=(64, 64),
                       mostrar_activaciones=False, aplicar_ajuste_contraste_camara=False):
    """
    Predice la clase de una nueva imagen usando el modelo CNN entrenado

    Args:
        imagen_path: Ruta a la imagen para predecir
        model: Modelo CNN entrenado
        label_to_class: Diccionario de mapeo de etiquetas a clases
        target_size: Tamaño objetivo para redimensionar la imagen
        mostrar_activaciones: Si mostrar activaciones de capas conv
        aplicar_ajuste_contraste_camara: Si aplicar ajuste de contraste para fotos de cámara

    Returns:
        pred_class: Clase predicha
        confidence: Confianza de la predicción
        probs: Probabilidades para todas las clases
    """
    try:
        # Cargar y preprocesar la imagen
        img = io.imread(imagen_path)

        # Preprocesamiento similar al entrenamiento
        if img.ndim == 3:
            if img.shape[2] == 4:  # RGBA
                img = img[:, :, 3]  # Usar canal alfa
            else:  # RGB
                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

        # Aplicar ajuste de contraste si es para imagen de cámara
        if aplicar_ajuste_contraste_camara:
            img_float = img.astype(np.float32)
            contrast_factor = 1.5 # Mismo factor que en el entrenamiento
            img_contrasted = (img_float - 128.0) * contrast_factor + 128.0
            img_contrasted = np.clip(img_contrasted, 0, 255)
            img = img_contrasted.astype(np.uint8)
            print("Ajuste de contraste aplicado a la imagen de cámara.")

        # Redimensionar
        img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) # Renombrar para claridad

        # Normalizar
        img_normalized = img_resized.astype(np.float32) / 255.0 # Renombrar para claridad

        # Añadir dimensiones (batch, height, width, channels)
        img_input = np.expand_dims(np.expand_dims(img_normalized, axis=-1), axis=0)

        # Visualizar imagen preprocesada
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))

        # Imagen original
        img_original = io.imread(imagen_path)
        if img_original.ndim == 3 and img_original.shape[2] > 3:
            img_original = img_original[:, :, :3]
        axes[0].imshow(img_original if img_original.ndim == 3 else img_original,
                      cmap='gray' if img_original.ndim == 2 else None)
        axes[0].set_title('Imagen Original')
        axes[0].axis('off')

        # Imagen preprocesada (antes de normalizar para visualización, o la normalizada)
        axes[1].imshow(img_resized, cmap='gray') # Mostrar img_resized para ver efecto de contraste
        axes[1].set_title(f'Imagen Preprocesada\n({target_size[0]}x{target_size[1]})')
        axes[1].axis('off')

        plt.tight_layout()
        plt.show()

        # Hacer predicción
        predictions = model.predict(img_input, verbose=0)
        pred_idx = np.argmax(predictions[0])
        pred_class = label_to_class[pred_idx]
        confidence = predictions[0][pred_idx]

        # Mostrar resultados
        print(f"🎯 Resultado de la predicción:")
        print(f"Clase predicha: {pred_class}")
        print(f"Confianza: {confidence:.4f} ({confidence*100:.2f}%)")

        # Mostrar todas las probabilidades
        print(f"\n📊 Probabilidades por clase:")
        sorted_indices = np.argsort(predictions[0])[::-1]
        for i, idx in enumerate(sorted_indices):
            prob = predictions[0][idx]
            print(f"  {i+1}. {label_to_class[idx]}: {prob:.4f} ({prob*100:.2f}%)")

        # Visualizar probabilidades
        plt.figure(figsize=(12, 6))

        # Gráfico de barras con todas las clases
        classes = [label_to_class[i] for i in range(len(label_to_class))]
        probs = predictions[0]
        colors = ['green' if i == pred_idx else 'lightblue' for i in range(len(probs))]

        bars = plt.bar(classes, probs, color=colors, edgecolor='navy', alpha=0.7)
        plt.xlabel('Clase')
        plt.ylabel('Probabilidad')
        plt.title('Probabilidades de predicción por clase')
        plt.ylim(0, 1)
        plt.grid(axis='y', alpha=0.3)

        # Añadir valores en las barras
        for bar, prob in zip(bars, probs):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{prob:.3f}', ha='center', va='bottom', fontsize=10)

        plt.tight_layout()
        plt.show()

        # Mostrar activaciones si se solicita
        if mostrar_activaciones:
            print("\n🔍 Visualizando activaciones de capas convolucionales...")
            try:
                visualizar_activaciones(model, img_input, idx_imagen=0)
            except Exception as e:
                print(f"Error al mostrar activaciones: {e}")

        return pred_class, confidence, predictions[0]

    except Exception as e:
        print(f"❌ Error al predecir la imagen: {e}")
        return None, None, None

# Función auxiliar para predicción masiva
def predecir_directorio(directorio_path, model, label_to_class, target_size=(64, 64)):
    """Predice todas las imágenes en un directorio"""
    extensiones = ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']
    imagenes = []
    for ext in extensiones:
        imagenes.extend(glob.glob(os.path.join(directorio_path, ext)))

    if not imagenes:
        print(f"No se encontraron imágenes en {directorio_path}")
        return

    print(f"🔍 Prediciendo {len(imagenes)} imágenes en {directorio_path}")

    resultados = []
    for img_path in imagenes:
        pred_class, confidence, probs = predecir_imagen_cnn(
            img_path, model, label_to_class, target_size, mostrar_activaciones=False
        )
        resultados.append({
            'archivo': os.path.basename(img_path),
            'prediccion': pred_class,
            'confianza': confidence
        })

    # Mostrar resumen
    df_resultados = pd.DataFrame(resultados)
    print("\n📋 Resumen de predicciones:")
    print(df_resultados.groupby('prediccion').agg({
        'confianza': ['count', 'mean', 'min', 'max']
    }).round(4))

    return df_resultados

# Ejemplo de uso (descomenta y ajusta la ruta cuando quieras usar)
# pred_class, confidence, probs = predecir_imagen_cnn(
#     "ruta/a/una/imagen.png",
#     model,
#     label_to_class,
#     mostrar_activaciones=True,
#     aplicar_ajuste_contraste_camara=True # Ejemplo para foto de cámara
# )

"""## Testeo con Fotos de Cámara

Esta sección permite probar el modelo con imágenes nuevas, por ejemplo, fotos tomadas con una cámara.

### 📸 Preparación de las imágenes de prueba:

1.  Crea una carpeta llamada `camera_test_data` en el mismo directorio que este notebook (`PC2/camera_test_data/`).
2.  Coloca las imágenes que deseas probar en esta carpeta. Pueden ser formatos PNG o JPG.
3.  Las imágenes serán preprocesadas (incluyendo el ajuste de contraste opcional) para que coincidan con el formato esperado por el modelo.

El siguiente código cargará las imágenes de esta carpeta y realizará predicciones.
"""

# Cargar el modelo si no está cargado (o recargarlo para asegurar que es el mejor)
print("Cargando el mejor modelo entrenado (mejor_modelo.h5) para testeo con fotos de cámara...")
try:
    model_cam_test = keras.models.load_model('mejor_modelo.h5')
    print("Modelo cargado exitosamente para testeo con fotos de cámara.")
except Exception as e:
    print(f"Error al cargar el modelo: {e}. Asegúrate de que el modelo 'mejor_modelo.h5' existe.")
    model_cam_test = None # Para evitar errores si la carga falla

if model_cam_test:
    # Ruta a la carpeta con imágenes de prueba de cámara
    ruta_fotos_camara = './camera_test_data/' # Ajusta si es necesario

    if not os.path.exists(ruta_fotos_camara):
        print(f"ADVERTENCIA: La carpeta {ruta_fotos_camara} no existe. Por favor, créala y añade imágenes.")
    else:
        extensiones_camara = ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']
        imagenes_camara = []
        for ext in extensiones_camara:
            imagenes_camara.extend(glob.glob(os.path.join(ruta_fotos_camara, ext)))

        if not imagenes_camara:
            print(f"No se encontraron imágenes en la carpeta: {ruta_fotos_camara}")
        else:
            print(f"\n🔍 Probando {len(imagenes_camara)} imágenes de la carpeta '{ruta_fotos_camara}':")
            for img_path_cam in imagenes_camara:
                print(f"\n--- Procesando imagen: {img_path_cam} ---")
                pred_class_cam, confidence_cam, probs_cam = predecir_imagen_cnn(
                    img_path_cam,
                    model_cam_test,
                    label_to_class,
                    target_size=input_shape[:2], # Usar el target_size del entrenamiento
                    mostrar_activaciones=False, # Puedes ponerlo a True para una imagen específica
                    aplicar_ajuste_contraste_camara=True # Aplicar ajuste de contraste
                )
                if pred_class_cam:
                    print(f"Predicción para {os.path.basename(img_path_cam)}: {pred_class_cam} (Confianza: {confidence_cam:.2f})")
else:
    print("No se pudo cargar el modelo. Testeo con fotos de cámara omitido.")

# Guardar el modelo CNN completo
def guardar_modelo_cnn(model, history, label_to_class,
                      nombre_base='modelo_cnn_caracteres'):
    """Guarda el modelo CNN y toda la información asociada"""

    # Guardar modelo en formato TensorFlow
    ruta_modelo = f"{nombre_base}.h5"
    model.save(ruta_modelo)
    print(f"✅ Modelo guardado en: {ruta_modelo}")

    # Guardar información del modelo
    info_modelo = {
        'arquitectura': arquitectura_elegida,
        'clases': clases,
        'label_to_class': label_to_class,
        'num_classes': num_classes,
        'input_shape': input_shape,
        'test_accuracy': test_accuracy,
        'test_loss': test_loss,
        'total_params': model.count_params(),
        'fecha_entrenamiento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
        'epochs_entrenados': len(history.history['accuracy']),
        'mejor_val_accuracy': max(history.history['val_accuracy']),
        'arquitectura_completa': model.to_json()
    }

    ruta_info = f"{nombre_base}_info.pkl"
    joblib.dump(info_modelo, ruta_info)
    print(f"✅ Información del modelo guardada en: {ruta_info}")

    # Guardar historial de entrenamiento
    ruta_history = f"{nombre_base}_history.pkl"
    joblib.dump(history.history, ruta_history)
    print(f"✅ Historial de entrenamiento guardado en: {ruta_history}")

    # Guardar pesos del modelo (formato más ligero)
    ruta_pesos = f"{nombre_base}_pesos.h5"
    model.save_weights(ruta_pesos)
    print(f"✅ Pesos del modelo guardados en: {ruta_pesos}")

    return ruta_modelo, ruta_info, ruta_history, ruta_pesos

def cargar_modelo_cnn(ruta_modelo='modelo_cnn_caracteres.h5',
                     ruta_info='modelo_cnn_caracteres_info.pkl'):
    """Carga el modelo CNN desde disco"""

    try:
        # Cargar modelo
        model = keras.models.load_model(ruta_modelo)
        print(f"✅ Modelo cargado desde: {ruta_modelo}")

        # Cargar información adicional
        if os.path.exists(ruta_info):
            info_modelo = joblib.load(ruta_info)
            print(f"✅ Información del modelo cargada desde: {ruta_info}")

            print(f"\n📊 Información del modelo:")
            print(f"Arquitectura: {info_modelo.get('arquitectura', 'No especificada')}")
            print(f"Clases: {info_modelo.get('clases', [])}")
            print(f"Precisión en prueba: {info_modelo.get('test_accuracy', 'N/A'):.4f}")
            print(f"Fecha de entrenamiento: {info_modelo.get('fecha_entrenamiento', 'N/A')}")
            print(f"Épocas entrenadas: {info_modelo.get('epochs_entrenados', 'N/A')}")
            print(f"Parámetros totales: {info_modelo.get('total_params', 'N/A'):,}")

            return model, info_modelo
        else:
            print(f"⚠️ No se encontró archivo de información en: {ruta_info}")
            return model, None

    except Exception as e:
        print(f"❌ Error al cargar el modelo: {e}")
        return None, None

# Guardar el modelo actual
print("💾 Guardando modelo CNN...")
rutas = guardar_modelo_cnn(model, history, label_to_class)

# Crear resumen del entrenamiento
resumen_df = pd.DataFrame({
    'Métrica': ['Precisión entrenamiento', 'Precisión validación', 'Precisión prueba',
                'Pérdida entrenamiento', 'Pérdida validación', 'Pérdida prueba',
                'Parámetros totales', 'Épocas entrenadas'],
    'Valor': [
        f"{history.history['accuracy'][-1]:.4f}",
        f"{history.history['val_accuracy'][-1]:.4f}",
        f"{test_accuracy:.4f}",
        f"{history.history['loss'][-1]:.4f}",
        f"{history.history['val_loss'][-1]:.4f}",
        f"{test_loss:.4f}",
        f"{model.count_params():,}",
        f"{len(history.history['accuracy'])}"
    ]
})

print(f"\n📋 Resumen del modelo entrenado:")
print(resumen_df.to_string(index=False))

# Ejemplo de cómo cargar el modelo (descomenta cuando sea necesario)
# modelo_cargado, info = cargar_modelo_cnn()

"""## 11. Conclusiones

En este notebook, hemos desarrollado un sistema completo de reconocimiento de caracteres escritos a mano utilizando Redes Neuronales Convolucionales (CNN) que incluye:

### 🎯 Características principales desarrolladas:

1. **📁 Sistema de carga de datos robusto**:
   - Carga automática desde carpetas organizadas por clase
   - Preprocesamiento optimizado para CNN
   - Guardado/carga eficiente con archivos .npy

2. **🏗️ Arquitectura CNN moderna**:
   - Múltiples opciones de arquitectura (básica, intermedia, avanzada)
   - Capas de BatchNormalization y Dropout para estabilidad
   - Configuración optimizada de hiperparámetros

3. **📊 Análisis post-entrenamiento exhaustivo**:
   - Visualización de errores con análisis de confianza
   - Activaciones de capas convolucionales
   - Métricas detalladas por clase
   - Distribución de confianza de predicciones

4. **🔍 Sistema de predicción completo**:
   - Predicción de imágenes individuales
   - Procesamiento masivo de directorios
   - Visualización de activaciones en tiempo real

### 📈 Ventajas sobre métodos tradicionales:

- **Mayor precisión**: Las CNN son superiores para reconocimiento de imágenes
- **Robustez**: Mejor manejo de variaciones en escritura y calidad de imagen
- **Escalabilidad**: Fácil extensión a más clases de caracteres
- **Interpretabilidad**: Visualización de qué aprende el modelo

### 🔧 Posibles mejoras futuras:

1. **Data Augmentation**: Rotar, escalar y deformar imágenes para mayor robustez
2. **Transfer Learning**: Usar modelos preentrenados como punto de partida
3. **Ensemble Methods**: Combinar múltiples modelos para mayor precisión
4. **Optimización de hiperparámetros**: Grid search o Bayesian optimization
5. **Arquitecturas más avanzadas**: ResNet, DenseNet, o Vision Transformers
6. **Regularización avanzada**: Label smoothing, mixup, cutmix

### 💡 Aplicaciones prácticas:

- Digitalización de documentos históricos
- Reconocimiento de formularios manuscritos
- Sistemas de captura de firmas
- Aplicaciones educativas de escritura
- Asistentes digitales para personas con discapacidades

Este sistema proporciona una base sólida para aplicaciones de reconocimiento de caracteres en el mundo real, con herramientas completas para análisis, debugging y mejora continua del modelo.
"""